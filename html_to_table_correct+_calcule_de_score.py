# -*- coding: utf-8 -*-
"""html to table correct+ calcule de score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_QJ6INTxPcDWLh8cOq0Rixr4-c0ytnC_
"""

# ================== Config ==================
RENAME_7MER_M8_TO_8MER = True         # Renommer 7mer-m8 en "8mer" (convention tolérante)
ALLOW_GU_AS_MATCH_FOR_CUSTOM = True   # Compter G:U comme "match" pour la seed personnalisée

# Seuils de clivage AGO2 (basés sur 2–12 et coeur 10–11)
AGO2_PROB_WC2_12_MIN = 11   # >= 11 positions WC sur 2..12
AGO2_PROB_GU2_12_MAX = 0    # pas de GU sur 2..12
AGO2_PROB_MM2_12_MAX = 0    # pas de mismatch sur 2..12

AGO2_POSS_WC2_12_MIN = 10   # >= 10 WC sur 2..12
AGO2_POSS_GU2_12_MAX = 1    # <= 1 GU
AGO2_POSS_MM2_12_MAX = 1    # <= 1 mismatch

# ================== Install ==================
!pip -q install pandas openpyxl beautifulsoup4 lxml

# ================== Imports ==================
import re
import pandas as pd
from google.colab import files
import openpyxl
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment
from bs4 import BeautifulSoup

# ================== Helpers ==================
def _is_nuc(c):
    return c.upper() in "ACGTU-"

def _clean_seq(s):
    s = ''.join(ch for ch in s if _is_nuc(ch))
    return s.upper().replace('T','U')

def _is_wc_pair(t,m):
    return (t,m) in {('A','U'),('U','A'),('C','G'),('G','C')}

def _is_wobble_gu(t,m):
    return (t,m) in {('G','U'),('U','G')}

def extract_aligned_pair_from_block(block):
    """
    Extrait deux lignes de séquence (même longueur) représentant cible et miRNA alignés.
    Retourne (t_seq, m_seq) ou (None, None).
    """
    if not block:
        return None, None
    lines = [l.rstrip('\n') for l in block.splitlines() if l.strip()!='']
    mid = []
    t_lab, m_lab = None, None
    for l in lines:
        m = re.search(r"^target\s*5'\s*(.*?)\s*3'", l, re.IGNORECASE)
        if m:
            t_lab = _clean_seq(m.group(1)); continue
        m = re.search(r"^miRNA\s*3'\s*(.*?)\s*5'", l, re.IGNORECASE)
        if m:
            m_lab = _clean_seq(m.group(1)); continue
        s = _clean_seq(l)
        if len(s) >= 4:
            mid.append(s)
    if len(mid) >= 2:
        for i in range(len(mid)):
            for j in range(i+1, len(mid)):
                if len(mid[i]) == len(mid[j]):
                    return mid[i], mid[j]
    if t_lab and m_lab and len(t_lab)==len(m_lab) and len(t_lab)>=4:
        return t_lab, m_lab
    return None, None

def _pair_type(tb, mb):
    if tb not in 'ACGU' or mb not in 'ACGU':
        return 'MM'
    if _is_wc_pair(tb, mb):
        return 'WC'
    if _is_wobble_gu(tb, mb):
        return 'GU'
    return 'MM'

def _seed_features(t_seq, m_seq, allow_gu=False):
    """
    t_seq: cible 5'->3'; m_seq: miRNA 3'->5'
    Retour: type seed (8mer/7mer/6mer/None), seed_map (2..8), nb_GU_seed, A1_base
    """
    n = len(m_seq)
    idx = lambda pos: n - pos  # miRNA pos from 5' -> index
    def inb(i): return 0 <= i < n
    def match(i):
        if not inb(i): return False
        pt = _pair_type(t_seq[i], m_seq[i])
        return (pt == 'WC') or (allow_gu and pt == 'GU')

    seed_types = []
    for pos in range(2, 9):
        i = idx(pos)
        pt = _pair_type(t_seq[i], m_seq[i]) if inb(i) else 'MM'
        seed_types.append(pt)

    map_char = {'WC':'|','GU':':','MM':'.'}
    seed_map = ''.join(map_char.get(pt,'.') for pt in seed_types)
    nb_GU_seed = sum(1 for pt in seed_types if pt=='GU')

    seed27 = all(match(idx(p)) for p in range(2,8))
    seed28 = seed27 and match(idx(8))
    i1 = idx(1)
    A1_base = t_seq[i1] if inb(i1) else ''
    t1A = (A1_base == 'A')

    if seed28:
        typ = '8mer' if t1A else '7mer-m8'
        score = 4 if t1A else 3
    elif seed27:
        typ = '7mer-A1' if t1A else '6mer'
        score = 2 if t1A else 1
    else:
        typ, score = None, 0

    return {'type': typ, 'score': score, 'seed_map': seed_map,
            'nb_GU_seed': nb_GU_seed, 'A1_base': A1_base}

def classify_site(block, allow_gu=False):
    """
    Essaie plusieurs orientations et garde la meilleure (par score seed).
    Retour: dict avec type, seed_map, nb_GU_seed, A1_base, t_seq, m_seq
    """
    t0, m0 = extract_aligned_pair_from_block(block)
    if not t0 or not m0 or len(t0)!=len(m0):
        return {'type':None, 'seed_map':'', 'nb_GU_seed':'', 'A1_base':'',
                't_seq':None, 'm_seq':None}

    cands = []
    combos = [
        (t0, m0),
        (t0, m0[::-1]),
        (m0, t0),
        (m0, t0[::-1]),
    ]
    for a,b in combos:
        if len(a)!=len(b):
            continue
        feat = _seed_features(a, b, allow_gu=allow_gu)
        feat['t_seq'] = a; feat['m_seq'] = b
        cands.append(feat)

    if not cands:
        return {'type':None, 'seed_map':'', 'nb_GU_seed':'', 'A1_base':'',
                't_seq':None, 'm_seq':None}

    cands.sort(key=lambda x: x['score'], reverse=True)
    return cands[0]

def condense_positions(pos_list):
    if not pos_list:
        return ''
    xs = sorted(set(int(p) for p in pos_list))
    ranges = []
    start = xs[0]
    prev = xs[0]
    for p in xs[1:]:
        if p == prev + 1:
            prev = p
        else:
            ranges.append((start, prev))
            start = p; prev = p
    ranges.append((start, prev))
    out = []
    for a,b in ranges:
        out.append(f"{a}" if a==b else f"{a}-{b}")
    return ','.join(out)

def compute_pairing_details(t_seq, m_seq):
    """
    Calcule cartes/compteurs d'appariements.
    """
    if not t_seq or not m_seq or len(t_seq)!=len(m_seq):
        return {}

    n = len(m_seq)
    idx_to_pos = lambda i: n - i  # i=0.. -> miRNA pos from 5'
    map_char = {'WC':'|','GU':':','MM':'.'}

    miRNA_3p_WC = []
    miRNA_3p_WC_GU = []
    wc_13_16 = gu_13_16 = 0
    wc_9_12 = 0

    wc_2_12 = gu_2_12 = mm_2_12 = 0
    wc_2_16 = gu_2_16 = mm_2_16 = 0

    pair_map = {}
    for i,(tb, mb) in enumerate(zip(t_seq, m_seq)):
        pos = idx_to_pos(i)
        pt = _pair_type(tb, mb)
        pair_map[pos] = pt

        if 2 <= pos <= 12:
            if pt == 'WC': wc_2_12 += 1
            elif pt == 'GU': gu_2_12 += 1
            else: mm_2_12 += 1

        if 2 <= pos <= 16:
            if pt == 'WC': wc_2_16 += 1
            elif pt == 'GU': gu_2_16 += 1
            else: mm_2_16 += 1

        if pos > 8:
            if pt == 'WC': miRNA_3p_WC.append(pos)
            if pt in ('WC','GU'): miRNA_3p_WC_GU.append(pos)

        if 13 <= pos <= 16:
            if pt == 'WC': wc_13_16 += 1
            elif pt == 'GU': gu_13_16 += 1

        if 9 <= pos <= 12 and pt == 'WC':
            wc_9_12 += 1

    central_10_11_WC = (pair_map.get(10) == 'WC' and pair_map.get(11) == 'WC')

    seed2_12_map = ''.join(map_char.get(pair_map.get(pos,'MM'),'.') for pos in range(2,13))

    det_13_16 = []
    for pos in range(13,17):
        pt = pair_map.get(pos, 'MM')
        lab = pt if pt in ('WC','GU') else 'MM'
        det_13_16.append(f"{pos}:{lab}")
    positions_13_16_detail = ','.join(det_13_16)

    return {
        'miRNA_3p_positions_WC': condense_positions(miRNA_3p_WC),
        'miRNA_3p_positions_WC_GU': condense_positions(miRNA_3p_WC_GU),
        'nb_WC_13_16': wc_13_16,
        'nb_GU_13_16': gu_13_16,
        'positions_13_16_detail': positions_13_16_detail,
        'central_10_11_WC': central_10_11_WC,
        'nb_WC_9_12': wc_9_12,
        'wc_2_12': wc_2_12,
        'gu_2_12': gu_2_12,
        'mm_2_12': mm_2_12,
        'seed2_12_map': seed2_12_map,
        'wc_2_16': wc_2_16,
        'gu_2_16': gu_2_16,
        'mm_2_16': mm_2_16
    }

def supplementary_strength(wc_13_16, total_13_16):
    if wc_13_16 >= 3:
        return 'fort'
    if wc_13_16 == 2:
        return 'modéré'
    if total_13_16 >= 3:
        return 'modéré (avec GU)'
    if total_13_16 == 2:
        return 'léger (avec GU)'
    return 'faible'

def interpret_effect(type_utr, seed_canon, seed_gu, wc_13_16, gu_13_16,
                     central_10_11_wc, wc_2_12, gu_2_12, mm_2_12):
    if central_10_11_wc \
       and wc_2_12 >= AGO2_PROB_WC2_12_MIN \
       and gu_2_12 <= AGO2_PROB_GU2_12_MAX \
       and mm_2_12 <= AGO2_PROB_MM2_12_MAX:
        ago2 = 'Probable'
    elif central_10_11_wc \
         and wc_2_12 >= AGO2_POSS_WC2_12_MIN \
         and gu_2_12 <= AGO2_POSS_GU2_12_MAX \
         and mm_2_12 <= AGO2_POSS_MM2_12_MAX:
        ago2 = 'Possible'
    else:
        ago2 = 'Non'

    good_seed = (seed_canon in ('8mer','7mer-m8','7mer-A1')) or (seed_gu in ('8mer','7mer-m8','7mer-A1'))
    total_13_16 = wc_13_16 + gu_13_16

    if ago2 != 'Non':
        action = 'Clivage AGO2 (siRNA-like) possible'
    else:
        if type_utr == '3UTR' and good_seed:
            action = "Dégradation ARNm probable" if total_13_16 >= 2 else "Dégradation ARNm probable (faible support 3')"
        elif good_seed and type_utr in ('5UTR','CDS'):
            action = "Répression traductionnelle plus probable (site hors 3'UTR)"
        else:
            action = "Répression traductionnelle plus probable (seed faible/non canonique)"

    return ago2, action

def compute_gu_wobble_info(block):
    t, m = extract_aligned_pair_from_block(block)
    if not t or not m or len(t)!=len(m):
        return {'has_GU': None, 'GU_count': None}
    gu = sum(1 for tb, mb in zip(t,m) if _is_wobble_gu(tb,mb))
    return {'has_GU': gu>0, 'GU_count': gu}

# ---- Parsing du nom Target -> Type UTR / Ensembl / Symbole ----
def parse_target_metadata(target_name):
    tokens = [t for t in re.split(r'[_\s:|]+', str(target_name).strip()) if t]

    Type_UTR = ''
    for tok in tokens:
        if re.fullmatch(r'(?:3UTR|UTR3)', tok, re.IGNORECASE):
            Type_UTR = '3UTR'; break
        if re.fullmatch(r'(?:5UTR|UTR5)', tok, re.IGNORECASE):
            Type_UTR = '5UTR'; break
        if re.fullmatch(r'CDS', tok, re.IGNORECASE):
            Type_UTR = 'CDS'; break

    Accession_Ensembl = ''
    for tok in tokens:
        if re.fullmatch(r'ENS[A-Z0-9]*[GTPR]\d+(?:\.\d+)?', tok, re.IGNORECASE):
            Accession_Ensembl = tok
            break

    Symbole_gene = ''
    for tok in reversed(tokens):
        if tok == Accession_Ensembl:
            continue
        if re.fullmatch(r'(?:3UTR|UTR3|5UTR|UTR5|CDS)', tok, re.IGNORECASE):
            continue
        if tok.isdigit():
            continue
        if re.search('[A-Za-z]', tok):
            Symbole_gene = tok
            break

    return {'Type_UTR': Type_UTR, 'Accession_Ensembl': Accession_Ensembl, 'Symbole_gene': Symbole_gene}

# ================== Parsing RNAhybrid ==================
def parse_rnahybrid_text(text):
    records = []
    record = None
    expect_length = None
    capturing_alignment = False
    align_lines = []
    dataset_id = None

    lines = text.splitlines()

    def finalize_record(rec, align_acc):
        if rec is None:
            return
        if 'interaction' not in rec and align_acc:
            rec['interaction'] = '\n'.join(align_acc)
        for k in ['target_length','miRNA_length','mfe_kcal_mol','p_value','Position','interaction']:
            rec.setdefault(k, None)

        # Découpage Target
        if 'Target' in rec and rec['Target']:
            meta = parse_target_metadata(rec['Target'])
            rec.update(meta)
        else:
            rec['Type_UTR'] = ''
            rec['Accession_Ensembl'] = ''
            rec['Symbole_gene'] = ''

        # Analyses d'alignement
        if rec.get('interaction'):
            canon = classify_site(rec['interaction'], allow_gu=False)
            rec['Type_seed_canonique'] = canon['type'] or ''
            rec['seed_map_canon_2_8'] = canon['seed_map'] or ''
            rec['A1_base'] = canon['A1_base'] or ''
            t_best = canon['t_seq']; m_best = canon['m_seq']

            custom = classify_site(rec['interaction'], allow_gu=ALLOW_GU_AS_MATCH_FOR_CUSTOM)
            seed_gu = custom['type'] or ''
            if RENAME_7MER_M8_TO_8MER and seed_gu == '7mer-m8':
                seed_gu = '8mer'
            rec['Type_seed_GU'] = seed_gu
            rec['seed_map_GU_2_8'] = custom['seed_map'] or ''
            rec['nb_GU_seed'] = custom['nb_GU_seed'] if custom['nb_GU_seed']!='' else ''

            if t_best is None or m_best is None:
                t_best = custom['t_seq']
                m_best = custom['m_seq']

            if t_best is not None and m_best is not None:
                pdets = compute_pairing_details(t_best, m_best)
                rec.update(pdets)
                total_13_16 = pdets['nb_WC_13_16'] + pdets['nb_GU_13_16']
                rec['supp3_force'] = supplementary_strength(pdets['nb_WC_13_16'], total_13_16)

                ago2, action = interpret_effect(
                    rec['Type_UTR'],
                    rec['Type_seed_canonique'],
                    rec['Type_seed_GU'],
                    pdets['nb_WC_13_16'],
                    pdets['nb_GU_13_16'],
                    pdets['central_10_11_WC'],
                    pdets['wc_2_12'],
                    pdets['gu_2_12'],
                    pdets['mm_2_12']
                )
                rec['AGO2_clivage_prediction'] = ago2
                rec['Interpretation_action'] = action
            else:
                for k in ['miRNA_3p_positions_WC','miRNA_3p_positions_WC_GU','nb_WC_13_16','nb_GU_13_16',
                          'positions_13_16_detail','central_10_11_WC','nb_WC_9_12','wc_2_12','gu_2_12','mm_2_12',
                          'seed2_12_map','wc_2_16','gu_2_16','mm_2_16','supp3_force','AGO2_clivage_prediction','Interpretation_action']:
                    rec[k] = ''

            gu = compute_gu_wobble_info(rec['interaction'])
            if gu['has_GU'] is None:
                rec['has_GU_wobble'] = ''
                rec['GU_wobble_count'] = ''
            else:
                rec['has_GU_wobble'] = 'Oui' if gu['has_GU'] else 'Non'
                rec['GU_wobble_count'] = gu['GU_count']
        else:
            for k in ['Type_seed_canonique','seed_map_canon_2_8','A1_base',
                      'Type_seed_GU','seed_map_GU_2_8','nb_GU_seed',
                      'miRNA_3p_positions_WC','miRNA_3p_positions_WC_GU',
                      'nb_WC_13_16','nb_GU_13_16','positions_13_16_detail',
                      'central_10_11_WC','nb_WC_9_12','wc_2_12','gu_2_12','mm_2_12',
                      'seed2_12_map','wc_2_16','gu_2_16','mm_2_16',
                      'supp3_force','AGO2_clivage_prediction','Interpretation_action',
                      'has_GU_wobble','GU_wobble_count']:
                rec[k] = ''
        records.append(rec)

    for raw in lines:
        l = raw.strip()

        m = re.match(r'^dataset:\s*(\S+)', l, re.IGNORECASE)
        if m:
            dataset_id = m.group(1)
            continue

        if l.lower().startswith('target:'):
            if record:
                finalize_record(record, align_lines)
                align_lines = []
                capturing_alignment = False
            record = {'dataset': dataset_id}
            record['Target'] = raw.split(':',1)[1].strip()
            expect_length = 'target'
            continue

        if record is None:
            continue

        if l.lower().startswith('length:'):
            m = re.search(r'length:\s*(\d+)', l, re.IGNORECASE)
            val = int(m.group(1)) if m else None
            if expect_length == 'target' and 'target_length' not in record:
                record['target_length'] = val; expect_length = None
            elif expect_length == 'miRNA' and 'miRNA_length' not in record:
                record['miRNA_length'] = val; expect_length = None
            else:
                if 'miRNA' in record and 'miRNA_length' not in record:
                    record['miRNA_length'] = val
                elif 'target_length' not in record:
                    record['target_length'] = val
            continue

        if l.lower().startswith('mirna:'):
            record['miRNA'] = raw.split(':',1)[1].strip()
            expect_length = 'miRNA'
            continue

        if l.lower().startswith('mfe:'):
            m = re.search(r'mfe:\s*([-\d.]+)', l, re.IGNORECASE)
            record['mfe_kcal_mol'] = float(m.group(1)) if m else None
            continue

        if l.lower().startswith('p-value'):
            m = re.search(r'p-value:\s*([0-9.eE+-]+)', l, re.IGNORECASE)
            record['p_value'] = float(m.group(1)) if m else None
            continue

        if l.lower().startswith('position'):
            m = re.search(r'position:\s*(\d+)', l, re.IGNORECASE)
            record['Position'] = int(m.group(1)) if m else None
            continue

        if re.search(r"^target\s*5'", l, re.IGNORECASE):
            capturing_alignment = True
            align_lines = [raw.strip()]
            continue

        if capturing_alignment:
            align_lines.append(raw.strip())
            if re.search(r"^miRNA\s*3'", l, re.IGNORECASE):
                record['interaction'] = '\n'.join(align_lines)
                capturing_alignment = False
            continue

    if record:
        finalize_record(record, align_lines)

    return records

# ================== Run: upload -> parse -> Excel ==================
def _normalize_rnahybrid_text(s):
    # Normaliser espaces/ponctuation
    s = s.replace('\xa0', ' ').replace('\u2009',' ').replace('\u202f',' ')
    s = re.sub(r'[：∶﹕]', ':', s)                        # colons "exotiques" -> :
    s = s.replace('’', "'").replace('‘', "'").replace('′', "'").replace('`', "'")  # 5’/3’ -> '

    # Filtrer les lignes parasites (HTML et TXT)
    skip_patterns = [
        r'^\s*version\s*:\s*rnahybrid\b',   # Version: RNAhybrid 2.2
        r'^\s*searching\s*$',               # searching
        r'^\s*dataset\s*:\s*.*$',           # dataset: 1 (ou autres)
        r'^\s*mde\s+of\b.*$',               # mde of xyz: -50.7
        r'^\s*individual\s+hits\s*$',       # Individual hits
    ]
    skip_res = [re.compile(p, re.IGNORECASE) for p in skip_patterns]
    lines = [ln for ln in s.splitlines() if not any(rx.search(ln) for rx in skip_res)]

    # Recoller les entêtes "Label:" si la valeur est sur la ligne suivante
    header = re.compile(r'^(dataset|target|miRNA|mirna|length|mfe|p[ -]?value|position)\s*:\s*$', re.I)
    out = []
    i = 0
    while i < len(lines):
        ln_raw = lines[i]
        ln = ln_raw.strip()
        m = header.match(ln)
        if m:
            label = m.group(1)
            if label.lower() in ('p value','pvalue'): label = 'p-value'
            if label.lower() == 'mirna': label = 'miRNA'
            j = i + 1
            while j < len(lines) and lines[j].strip() == '':
                j += 1
            if j < len(lines):
                next_ln = lines[j].strip()
                if not header.match(next_ln):
                    out.append(f"{label}: {next_ln}")
                    i = j + 1
                    continue
        out.append(ln_raw)
        i += 1

    text = '\n'.join(out)
    text = re.sub(r'\r', '', text)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text

print("Sélectionnez votre fichier .txt ou .html (résultat RNAhybrid).")
uploaded = files.upload()
if not uploaded:
    raise SystemExit("Aucun fichier sélectionné.")
fname = list(uploaded.keys())[0]
raw_bytes = uploaded[fname]

# Extraction du texte selon le type de fichier
ext = fname.lower().rsplit('.', 1)[-1] if '.' in fname else ''
if ext in ('html', 'htm'):
    html = raw_bytes.decode('utf-8', errors='ignore')
    try:
        soup = BeautifulSoup(html, 'lxml')
    except Exception:
        soup = BeautifulSoup(html, 'html.parser')
    for br in soup.find_all('br'):
        br.replace_with('\n')
    text = soup.get_text('\n', strip=False)
else:
    text = raw_bytes.decode('utf-8', errors='ignore')

# Normalisation + filtrage des lignes à ignorer
text = _normalize_rnahybrid_text(text)

records = parse_rnahybrid_text(text)
if not records:
    print("Aucun enregistrement détecté. Aperçu du texte normalisé (500 premiers caractères) :")
    print(text[:500])
    raise SystemExit("Aucun enregistrement détecté. Vérifiez le format.")

df = pd.DataFrame(records)

col_mapping = {
    'Target': 'Target',
    'Type_UTR': 'Type_UTR',
    'Accession_Ensembl': 'Accession_Ensembl',
    'Symbole_gene': 'Symbole_gene',
    'target_length': 'Longueur_cible',
    'miRNA': 'MiRNA_ID',
    'miRNA_length': 'Longueur_miRNA',
    'mfe_kcal_mol': 'mfe_kcal/mol',
    'p_value': 'p_value',
    'Position': 'Position',
    'interaction': 'Interaction_miRNA-Target',

    'Type_seed_canonique': 'Type_seed_canonique',
    'seed_map_canon_2_8': 'seed2-8_canon(|=:)',
    'A1_base': 'A1_base_cible',

    'Type_seed_GU': 'Type_seed_GU',
    'seed_map_GU_2_8': 'seed2-8_GU(|=:)',
    'nb_GU_seed': 'nb_GU_seed',

    'seed2_12_map': 'seed2-12_GU(|=:)',

    "miRNA_3p_positions_WC": "miRNA_3p_positions_WC(>8)",
    "miRNA_3p_positions_WC_GU": "miRNA_3p_positions_WC+GU(>8)",
    'nb_WC_13_16': 'nb_WC_13_16',
    'nb_GU_13_16': 'nb_GU_13_16',
    'positions_13_16_detail': 'positions_13_16_detail',
    'supp3_force': "supp3_force(13-16)",

    'central_10_11_WC': 'central_10_11_WC',
    'nb_WC_9_12': 'nb_WC_9_12',
    'wc_2_12': 'wc_2_12',
    'gu_2_12': 'gu_2_12',
    'mm_2_12': 'mm_2_12',

    'wc_2_16': 'wc_2_16',
    'gu_2_16': 'gu_2_16',
    'mm_2_16': 'mm_2_16',

    'AGO2_clivage_prediction': 'AGO2_clivage_prediction',
    'Interpretation_action': 'Interpretation_action',

    'has_GU_wobble': 'GU_non_canonique',
    'GU_wobble_count': 'nb_GU_total'
}

for k in col_mapping:
    if k not in df.columns:
        df[k] = None

df_out = df.rename(columns=col_mapping)

df_out = df_out[['Target','Type_UTR','Accession_Ensembl','Symbole_gene',
                 'Longueur_cible','MiRNA_ID','Longueur_miRNA',
                 'mfe_kcal/mol','p_value','Position',
                 'Interaction_miRNA-Target',

                 'Type_seed_canonique','seed2-8_canon(|=:)','A1_base_cible',
                 'Type_seed_GU','seed2-8_GU(|=:)', 'nb_GU_seed',
                 'seed2-12_GU(|=:)',

                 "miRNA_3p_positions_WC(>8)","miRNA_3p_positions_WC+GU(>8)",
                 'positions_13_16_detail','nb_WC_13_16','nb_GU_13_16',"supp3_force(13-16)",

                 'central_10_11_WC','nb_WC_9_12',
                 'wc_2_12','gu_2_12','mm_2_12',

                 'wc_2_16','gu_2_16','mm_2_16',

                 'AGO2_clivage_prediction','Interpretation_action',
                 'GU_non_canonique','nb_GU_total']]

out_name = 'RNAhybrid_parsed.xlsx'
with pd.ExcelWriter(out_name, engine='openpyxl') as writer:
    df_out.to_excel(writer, index=False, sheet_name='RNAhybrid')
    ws = writer.sheets['RNAhybrid']
    for col_idx, col_name in enumerate(df_out.columns, start=1):
        width = 80 if col_name == 'Interaction_miRNA-Target' else max(12, min(36, int(max([len(str(x)) for x in df_out[col_name].fillna('')] + [len(col_name)])*1.1)))
        ws.column_dimensions[get_column_letter(col_idx)].width = width
    inter_idx = list(df_out.columns).index('Interaction_miRNA-Target') + 1
    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=inter_idx, max_col=inter_idx):
        for cell in row:
            cell.alignment = Alignment(wrap_text=True, vertical='top')

# Alerte si Target est resté vide (diagnostic)
if df_out['Target'].fillna('').eq('').all():
    print("Attention: Tous les 'Target' sont vides après parsing. Partage un petit extrait de 20–30 lignes autour des blocs 'Target' et de l'alignement pour adapter le parseur si besoin.")

print(f"{len(df_out)} lignes exportées -> {out_name}")
files.download(out_name)

from google.colab import drive
drive.mount('/content/drive')

"""calcule de score

"""

import numpy as np


from Bio import SeqIO

# ========== FONCTION POUR CHARGER LES SEQUENCES UTR ==========
def load_utr_sequences(fasta_file):
    utr_dict = {}
    for record in SeqIO.parse(fasta_file, "fasta"):
        desc = record.description
        # extraire le nom du gène à la fin (après le dernier '_')
        gene_name = desc.split("_")[-1].split()[0].upper()
        utr_dict[gene_name] = str(record.seq).upper()
    return utr_dict

# ========== FONCTION POUR CALCULER LE %AU AUTOUR D'UN SITE ==========
def au_content_window(seq, start, window=30):
    """
    seq : séquence complète de l'UTR
    start : position du site (0-based)
    window : nombre de nucléotides autour du site (par défaut ±15)
    """
    half = window // 2
    seq_len = len(seq)
    w_start = max(start - half, 0)
    w_end = min(start + half, seq_len)
    sub_seq = seq[w_start:w_end]
    if len(sub_seq) == 0:
        return 0
    au_count = sub_seq.count("A") + sub_seq.count("U") + sub_seq.count("T")
    return au_count / len(sub_seq)

# ========== CHARGER LES SEQUENCES UTR ==========
# Corrected file path to load UTR sequences from a FASTA file
utr_sequences = load_utr_sequences("/content/drive/MyDrive/fichier_fusionne_avec_gene_UTR.fasta")

print("Exemples de gènes chargés :", list(utr_sequences.keys())[:10])

# ========== CALCUL DU AU-CONTENT ==========
au_values = []
for idx, row in df.iterrows():
    gene = row['Symbole_gene'].upper()
    pos = row.get('Position', None)
    if gene in utr_sequences and pos is not None:
        try:
            pos_int = int(pos)
            # The position from RNAhybrid output is 1-based, convert to 0-based
            au = au_content_window(utr_sequences[gene], pos_int - 1, window=30)
        except:
            au = 0.5
    else:
        au = 0.5
    au_values.append(au)

df['AU_content'] = au_values
print("✅ AU-content calculé pour tous les gènes")






# ========== 1. Score seed canonique ==========
seed_scores = {
    "8mer": 4,
    "7mer-m8": 3,
    "7mer-A1": 2,
    "6mer": 1,
    "non_canonique": 0
}
df["score_seed_num"] = df["Type_seed_canonique"].map(seed_scores).fillna(0)

# ========== 2. Normalisation mfe ==========
print(df.columns.tolist())

df["mfe_norm"] = df["mfe_kcal_mol"] / df["target_length"]

# ========== 3. AGO2 score ==========
def ago2_score(val):
    if isinstance(val, str):
        if "Probable" in val:
            return 2
        elif "Possible" in val:
            return 1
    return 0
df["AGO2_score"] = df["AGO2_clivage_prediction"].apply(ago2_score)

# ========== 5. Nombre de sites par gène ==========
df["nb_sites_gene"] = df.groupby("Symbole_gene")["Symbole_gene"].transform("count")

# ========== 6. Pondération par gène ==========
gene_weights = {
    "APP": 1.0, "PSEN1": 1.0, "PSEN2": 1.0, "APOE": 1.0,
    "SORL1": 0.5, "ABCA7": 0.5, "TREM2": 0.5, "CLU": 0.5,
    "CR1": 0.5, "PICALM": 0.5, "ADAM10": 0.5, "BDNF": 0.5,
    "IGF1R": 0.5, "SIRT1": 0.5, "PLD3": 0.5, "DISC1": 0.5,
    "DRD1": 0.5, "CCND2": 0.5, "NEFL": 0.5, "NEFH": 0.5,
    "FBN2": 0.1, "SCL27A6": 0.1, "DYM": 0.1, "TIAM1": 0.1,
    "VWA5B1": 0.1, "MOB1A": 0.1, "RPL23": 0.1, "LASP1": 0.1,
    "PDE4D": 0.1
}
df["gene_weight"] = df["Symbole_gene"].map(gene_weights).fillna(0.1)
# ========== Mapping supp3_force(13-16) en valeurs numériques ==========
supp3_mapping = {
    "fort": 3,
    "modéré": 2,
    "modéré (avec GU)": 1.5,
    "léger": 1,
    "léger (avec GU)": 0.5,
    "faible": 0
}

# Création d'une nouvelle colonne numérique
df["supp3_force_num"] = df["supp3_force"].map(supp3_mapping).fillna(0)


# ========== 7. Calcul du score final ==========
w1, w2, w3, w4, w5, w6 = 2.0, 1.5, 1.0, 1.0, 1.0, 2.0

df["Score_final"] = (
    w1 * df["score_seed_num"] +
    w2 * (-df["mfe_norm"]) +
    w3 * df["AU_content"] +
    w4 * df["supp3_force_num"] +
    w5 * df["AGO2_score"] +
    w6 * df["gene_weight"]
)

# Trier par score décroissant
df_sorted = df.sort_values("Score_final", ascending=False)

# Sauvegarde dans un nouvel Excel avec score
output_file = "scoring_miRNA_targets sans mfe miRNA avec mfe.xlsx"
df_sorted.to_excel(output_file, index=False)

print(f"✅ Score calculé avec AU-content réel et sauvegardé dans {output_file}")

"""le code pour le fichier qui contient le MFE de de mirRNA

"""

!pip install biopython

from google.colab import drive

# ================== 1. Monter Google Drive ==================
drive.mount('/content/drive')

# ================== Imports ==================
import pandas as pd
import numpy as np
from Bio import SeqIO

# ================== 2. Importer ton fichier Excel ==================
# ⚠️ Remplace le chemin par ton vrai fichier
input_file = "/content/drive/MyDrive/RNAhybrid_parsed avec mfe miRNA.xlsx"
df = pd.read_excel(input_file)

# ================== 3. Charger les séquences UTR ==================
def load_utr_sequences(fasta_file):
    utr_dict = {}
    for record in SeqIO.parse(fasta_file, "fasta"):
        desc = record.description
        gene_name = desc.split("_")[-1].split()[0].upper()
        utr_dict[gene_name] = str(record.seq).upper()
    return utr_dict

utr_sequences = load_utr_sequences("/content/drive/MyDrive/fichier_fusionne_avec_gene_UTR.fasta")

# ================== 4. Fonction AU-content ==================
def au_content_window(seq, start, window=30):
    half = window // 2
    seq_len = len(seq)
    w_start = max(start - half, 0)
    w_end = min(start + half, seq_len)
    sub_seq = seq[w_start:w_end]
    if len(sub_seq) == 0:
        return 0
    au_count = sub_seq.count("A") + sub_seq.count("U") + sub_seq.count("T")
    return au_count / len(sub_seq)

# Calcul AU-content
au_values = []
for idx, row in df.iterrows():
    gene = str(row['Symbole_gene']).upper()
    pos = row.get('Position', None)
    if gene in utr_sequences and pos is not None:
        try:
            pos_int = int(pos)
            au = au_content_window(utr_sequences[gene], pos_int, window=30)
        except:
            au = 0.5
    else:
        au = 0.5
    au_values.append(au)

df['AU_content'] = au_values
print("✅ AU-content calculé pour tous les gènes")

# ================== 5. Scores existants ==================
seed_scores = {"8mer": 4, "7mer-m8": 3, "7mer-A1": 2, "6mer": 1, "non_canonique": 0}
df["score_seed_num"] = df["Type_seed_canonique"].map(seed_scores).fillna(0)

# Normalisation MFE interaction
print(df.columns.tolist())
df["mfe_norm"] = df["mfe_kcal/mol"] / df["Longueur_cible"]

# AGO2
def ago2_score(val):
    if isinstance(val, str):
        if "Probable" in val:
            return 2
        elif "Possible" in val:
            return 1
    return 0
df["AGO2_score"] = df["AGO2_clivage_prediction"].apply(ago2_score)

# Nombre de sites par gène
df["nb_sites_gene"] = df.groupby("Symbole_gene")["Symbole_gene"].transform("count")

# Pondération gènes
gene_weights = {
    "APP": 1.0, "PSEN1": 1.0, "PSEN2": 1.0, "APOE": 1.0,
    "SORL1": 0.5, "ABCA7": 0.5, "TREM2": 0.5, "CLU": 0.5,
    "CR1": 0.5, "PICALM": 0.5, "ADAM10": 0.5, "BDNF": 0.5,
    "IGF1R": 0.5, "SIRT1": 0.5, "PLD3": 0.5, "DISC1": 0.5,
    "DRD1": 0.5, "CCND2": 0.5, "NEFL": 0.5, "NEFH": 0.5,
    "FBN2": 0.1, "SCL27A6": 0.1, "DYM": 0.1, "TIAM1": 0.1,
    "VWA5B1": 0.1, "MOB1A": 0.1, "RPL23": 0.1, "LASP1": 0.1,
    "PDE4D": 0.1
}
df["gene_weight"] = df["Symbole_gene"].map(gene_weights).fillna(0.1)

# supp3_force → numérique
supp3_mapping = {
    "fort": 3, "modéré": 2, "modéré (avec GU)": 1.5,
    "léger": 1, "léger (avec GU)": 0.5, "faible": 0
}
df["supp3_force_num"] = df["supp3_force(13-16)"].map(supp3_mapping).fillna(0)

# ================== 6. Ajouter la stabilité thermodynamique miRNA ==================
#df["MiRNA_mfe_norm"] = df["MiRNA_mfe_kcal/mol"] / df["Longueur_miRNA"]

# ================== 7. Score final ==================
w1, w2, w3, w4, w5, w6 = 2.0, 1.5, 1.0, 1.0, 1.0, 2.0

df["Score_final"] = (
    w1 * df["score_seed_num"] +
    w2 * (-df["mfe_norm"]) +
    w3 * df["AU_content"] +
    w4 * df["supp3_force_num"] +
    w5 * df["AGO2_score"] +
    w6 * df["gene_weight"] #+
    #w7 * (-df["MiRNA_mfe_norm"])   # stabilité miRNA (plus stable → plus favorable)
)

# ================== 8. Sauvegarde ==================
df_sorted = df.sort_values("Score_final", ascending=False)
output_file = "/content/drive/MyDrive/scoring_miRNA_targets_sans mfe miRNA_avec mfe.xlsx"
df_sorted.to_excel(output_file, index=False)

print(f"✅ Score calculé avec AU-content et stabilité miRNA, sauvegardé dans {output_file}")